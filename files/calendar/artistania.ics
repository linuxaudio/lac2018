BEGIN:VCALENDAR
VERSION:2.0
CALSCALE:GREGORIAN
PRODID:-//SabreDAV//SabreDAV//EN
X-WR-CALNAME:artistania (lac2018)
X-APPLE-CALENDAR-COLOR:#e78074
BEGIN:VTIMEZONE
TZID:Europe/Berlin
BEGIN:DAYLIGHT
TZOFFSETFROM:+0100
TZOFFSETTO:+0200
TZNAME:CEST
DTSTART:19700329T020000
RRULE:FREQ=YEARLY;BYMONTH=3;BYDAY=-1SU
END:DAYLIGHT
BEGIN:STANDARD
TZOFFSETFROM:+0200
TZOFFSETTO:+0100
TZNAME:CET
DTSTART:19701025T030000
RRULE:FREQ=YEARLY;BYMONTH=10;BYDAY=-1SU
END:STANDARD
END:VTIMEZONE
BEGIN:VEVENT
CREATED:20180502T225610
DTSTAMP:20180502T225610
LAST-MODIFIED:20180502T225610
UID:K57B60WTJ79G70TEPH8HR
SUMMARY:Sentire
CLASS:PUBLIC
DESCRIPTION:Author: Marcello Lussana\nType: Installation\nTopics: Audio and
  Music Languages\, Interactive Art\, Music Composition\, Projects Realized
  using Linux Audio\, Signal Processing and Sound Synthesis\nKeywords: embo
 diement\, interactive\, sound\, installation\, performance\nAbstract: Sent
 ire is an Italian word that means both to hear and to feel. The project is
  about exploring the fine mixture of these two senses and\, particularly\,
  to their amplification and morphing.\n\n'Sentire' project was initiated b
 y two Berlin-based artists Marcello Lussana and Olga Kozmanidze in 2016. T
 he project consists of two parts: immersive performance series based on in
 teractive sound and PhD research on human perception. In the course of the
  project we have been using a device (bracelets) connecting two people to 
 the sound system and tracking distance and touch events between them. We a
 pply and constantly develop a method of device usage according to which pa
 rticipants proceed through a scenario of two phases interaction. Depending
  on distance and touch between them different sounds are triggered and cha
 nging\, creating an instant sound feedback. Gradually both hearing and sen
 se of touch morth one into another giving a chance to perceive one's body 
 on a deep level.\n\nThe interactive system has been designed with the Supe
 rcollider software and it runs on Linux Mint.\nID: 17
STATUS:CONFIRMED
DTSTART;TZID=Europe/Berlin:20180609T200000
DTEND;TZID=Europe/Berlin:20180610T000000
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203543
DTSTAMP:20180426T203543
LAST-MODIFIED:20180426T205736
UID:RQXZO4LQOUZEBWDH6T4YC
SUMMARY:TXTED - interactive audio-visual performance using open-source musi
 cal machine learning interaction
CLASS:PUBLIC
STATUS:CONFIRMED
DESCRIPTION:Author: Shawn Trail\nType: Performance\nKeywords: NIME\, Pureda
 ta\, Raspberry Pi\nAbstract: This is a proposal to perform a new body of w
 ork using a new pitched percussion hyperinstrument system featuring a mach
 ine learning tool designed for music performance. All software was designe
 d in Puredata and runs on a Raspberry Pi with multichannel audio in/out. T
 he framework consists of custom idiomatic gesture interfaces and processin
 g software for an electric lamellophone with embedded gesture sensing. The
  instrumental framework is accompanied by an interactive video synthesizer
  built in GEM and also running on a Raspberry Pi\, networked together wire
 lessly. The project represents the culmination of the Phd research recentl
 y completed by the artist [1][2].\n\n1.Non-invasive sensing and gesture co
 ntrol for pitched percussion hyper-instruments using the Kinect.\nS Trail\
 , M Dean\, G Odowichuk\, TF Tavares\, PF Driessen\, WA Schloss\, G Tzaneta
 kis. NIME 2012.\n\n2. El-Lamellophone A Low-cost\, DIY\, Open Framework fo
 r Acoustic Lemellophone Based Hyperinstruments.\nS Trail\, D MacConnell\, 
 L Jenkins\, J Snyder\, G Tzanetakis\, PF Driessen. NIME\, 2014.\nID: 56
DTSTART;TZID=Europe/Berlin:20180609T210000
DTEND;TZID=Europe/Berlin:20180609T211500
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203626
DTSTAMP:20180426T203626
LAST-MODIFIED:20180426T205712
UID:AS2CZUECWT9ILZ5TBVHJKG
SUMMARY:COSMO
CLASS:PUBLIC
STATUS:CONFIRMED
DESCRIPTION:Author: Felix Hofmann\nType: Performance\nKeywords: performance
 \, saxophone\, raspberry pi\, csound\nAbstract: COSMO Collective is an ope
 n musical collaboration for musicians using DIY electronics and custom sof
 tware written in Csound. There is no definite musical style\, though it co
 uld perhaps be characterized as electro-acoustic\nimprovisation. The focus
  is on the exploration of sound and timbre\, rather than traditional harmo
 nics and rhythm\, and exploiting the powers of Csound in this pursuit.\nID
 : 21
DTSTART;TZID=Europe/Berlin:20180609T220000
DTEND;TZID=Europe/Berlin:20180609T221000
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203648
DTSTAMP:20180426T203648
LAST-MODIFIED:20180426T205710
UID:5FZFBEGNYVRD7CMYP6ZIPQ
SUMMARY:Tessellations
CLASS:PUBLIC
STATUS:CONFIRMED
DESCRIPTION:Author: José Rafael Subía Valdez\nType: Performance\nTopics: 
 Live Performance\, Music Composition\nKeywords: live electronics\, pure da
 ta\nAbstract: Tessellations plays with the repetition of material generate
 d by manipulating the interval structure of the chord and submitting it to
  short processes that I generate myself in Python and execute them inside 
 PD with the py object. This piece is an experimentation on the way I link 
 time\, material and narrative. The “tessellated” object not only morph
 s the musical material but also the space where it occurs and the performe
 r responsible for it – player or computer –. Furthermore\, the piece h
 as 2 solos\, one in which the performer improvises based on visual cues an
 d musical anchor points\, and the other which was generated algorithmicall
 y and is “written” on the score\, this incorporates the idea of the ac
 t of composition as the tessellated object itself.\nID: 23
DTSTART;TZID=Europe/Berlin:20180609T223000
DTEND;TZID=Europe/Berlin:20180609T224500
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203714
DTSTAMP:20180426T203714
LAST-MODIFIED:20180426T205706
UID:89D26VV861P10OJJV4U5XPB
SUMMARY:mathr performs with Clive
CLASS:PUBLIC
STATUS:CONFIRMED
DESCRIPTION:Author: Claude Heiland-Allen\nType: Performance\nTopics: Live C
 oding\nKeywords: audio\, live-coding\, performance\, C\nAbstract: Claude H
 eiland-Allen (https://mathr.co.uk) is an artist from London interested in 
 the complex emergent behaviour of simple systems\, unusual geometries\, an
 d mathematical aesthetics.\n\nClive is an audio live-coding skeleton\, imp
 lemented in C. It supports a two-phase edit-commit coding cycle allowing l
 ong-lived signal processing graphs to be modified without interrupting the
  sound.\n\nPerformance with Clive usually involves pre-preparation\, from 
 simple unit generators up to more complete compositions. The live-coding a
 spect involves editing a file in the performer’s favourite text editor\,
  with the act of saving with Ctrl-S or other shortcut being timed to allow
  the new code to start executing in sync after the latency of compilation.
 \nID: 22
DTSTART;TZID=Europe/Berlin:20180609T230000
DTEND;TZID=Europe/Berlin:20180609T232000
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203733
DTSTAMP:20180426T203733
LAST-MODIFIED:20180426T205704
UID:WBH7I8IRNTJ55DKC4QYSA6
SUMMARY:The Electronic Orchestra Berlin: The Metaphysics of Notation
CLASS:PUBLIC
STATUS:CONFIRMED
LOCATION:
DESCRIPTION:Author: Henrik von Coler & David Runge\nType: Performance\nKeyw
 ords: Performance\, Live Electronics\, Modular Synth\, Live Spatialization
 \, VBAP\, Ambisonics\, Graphical Scores\nAbstract: 12 electronic and elect
 roacoustic instruments\, live\nspatialized on a 12-speaker system - the El
 ectronic\nOrchestra Charlottenburg (EOC)\, a project of the Electronic\nMu
 sic Studio at TU Berlin\, explores means of organizing and\nspatializing t
 he seemingly infinite diversity of electronic\nsounds in a larger ensemble
 .\n\nThe Metaphysics of Notation (2008)\, by Mark Applebaum\, is a\ngraphi
 cal score with a length of 22 meters\, divided into 12\npanels.For the int
 erpretation of the score\, each instrument is assigned one or several pane
 ls. The piece is performed\nwithout a fixed time grid.\nThe performance wi
 ll be spatialized using the SSR\, PD and\nPython\, running on a Linux Serv
 er with Ubuntu Studio. The\nserver is remote controlled by the sound direc
 tor via OSC and various input devices. Inputs and outputs are managed with
  a RME MADI card and several AD/DA converters.\nID: 47
DTSTART;TZID=Europe/Berlin:20180609T233000
DTEND;TZID=Europe/Berlin:20180609T234500
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203521
DTSTAMP:20180426T203521
LAST-MODIFIED:20180426T205740
UID:1HW9S4VKBN2TS2ON79ERZ
SUMMARY:Pick It Up
CLASS:PUBLIC
STATUS:CONFIRMED
DESCRIPTION:Author: Krzysztof Gawlas\nType: Performance\nTopics: Interactiv
 e Art\, Media Art\, Music Composition\, Signal Processing and Sound Synthe
 sis\, Sound Spatialization\nKeywords: live performance\, prepared guitar\n
 Abstract: Composition for prepared electric guitar and live electronics (S
 uperCollider)\, with multichannel spatialization.\nID: 49
DTSTART;TZID=Europe/Berlin:20180609T203000
DTEND;TZID=Europe/Berlin:20180609T204000
END:VEVENT
BEGIN:VEVENT
CREATED:20180426T203602
DTSTAMP:20180426T203602
LAST-MODIFIED:20180426T205714
UID:KGZ7YDVU9NR2QDG0KJDKN
SUMMARY:Gestural Performance 2
CLASS:PUBLIC
STATUS:CONFIRMED
DESCRIPTION:Author: Joao Pais\nType: Performance\nKeywords: gestural perfor
 mance\, leapmotion\, pure data\nAbstract: This semi-improvised performance
  is the next step of an ongoing research for a gestural performance instru
 ment being developed by Pais. Using the LeapMotion sensor together with cu
 stom-made gesture interpretation and synthesis objects in Pure Data\, the 
 expressiveness of the performer's hand movements is reflected in the expre
 ssiveness of the sound that is produced and in its integration in space in
  a multichannel setup. The aim is to produce a developing event\, where th
 e gestures visible to the audience acquire a new meaning in each new sound
  context present in during the performance.\nID: 27
DTSTART;TZID=Europe/Berlin:20180609T213000
DTEND;TZID=Europe/Berlin:20180609T214500
END:VEVENT
END:VCALENDAR
